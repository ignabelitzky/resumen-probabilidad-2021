{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55060ba9",
   "metadata": {},
   "source": [
    "# *Capítulo 5 - Distribuciones de probabilidad conjunta y muestras aleatorias*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece36a0a",
   "metadata": {},
   "source": [
    "## 5.1 Variables aleatorias conjuntamente distribuidas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3262b7f9",
   "metadata": {},
   "source": [
    "### Dos variables aleatorias discretas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4627777",
   "metadata": {},
   "source": [
    "**Definición:** Sean $X$ e $Y$ dos variables aleatorias discretas definidas en el espacio muestral $S$ de un experimento. La **función de masa de probabilidad conjunta** $p(x, y)$ se define para cada par de números $(x,y)$ como"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b516bd",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "    p(x, y) = P(X = x \\land Y = y)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2271d91",
   "metadata": {},
   "source": [
    "Debe ser el caso que $p(x, y) \\ge 0$ y $\\sum_{x} \\sum_{y} p(x,y) = 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365f4898",
   "metadata": {},
   "source": [
    "Ahora sea $A$ cualquier conjunto compuesto de pares de valores $(x, y)$ (e.g. $A = \\{(x, y): x + y = 5\\}$ o $\\{(x, y): max(x, y) \\le 3\\}$). Entonces la probabilidad $P[(X, Y) \\in A]$ se obtiene sumando la función de masa de probabilidad conjunta incluídos todos los pares en $A$:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1464b8c8",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "    P[(X, Y) \\in A] = \\sum_{(x,y)} \\sum_{\\in A} p(x, y)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c26bf9",
   "metadata": {},
   "source": [
    "**Definición:** La **función de masa de probabilidad marginal de $X$,** denotada por $p_{x}(x)$, esta dada por"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbbbf04",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "    p_{x}(x) = \\sum_{y:p(x, y)>0} p(x,y) && \\text{para cada valor posible $x$}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f328e76",
   "metadata": {},
   "source": [
    "De manera similar, la **función de masa de probabilidad marginal de $Y$** es"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e7f4d2",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "    p_{y}(y) = \\sum_{x:p(x,y)>0} p(x,y) && \\text{para cada valor posible $y$}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52066978",
   "metadata": {},
   "source": [
    "### Dos variables aleatorias continuas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca34d193",
   "metadata": {},
   "source": [
    "**Definición:** Sean $X$ e $Y$ variables aleatorias continuas. Una **función de densidad de probabilidad conjunta** $f(x, y)$ para estas dos variables es una función que satisface $f(x, y) \\ge 0$ y $\\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} f(x, y)\\ dy \\ dx = 1$. Entonces para cualquier conjunto $A$ en dos dimensiones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa203ff",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "    P[(X, Y) \\in A] = \\int_{A} \\int f(x,y)\\ dx\\ dy\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc092df",
   "metadata": {},
   "source": [
    "En particular, si $A$ es el rectángulo bidimensional $\\{(x, y): a \\le x \\le b, c \\le y \\le d\\}$, entonces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a98d11",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "    P[(X,\\ Y) \\in A] = P(a \\le X \\le b,\\ c \\le Y \\le d) = \\int_{a}^{b} \\int_{c}^{d} f(x, y)\\ dy\\ dx\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e187cd3f",
   "metadata": {},
   "source": [
    "---\n",
    "Se puede considerar que $f(x,\\ y)$ específica una superficie situada a una altura $f(x,\\ y)$ encima del punto $(x,\\ y)$ en un sistema de coordenadas tridimensional. Entonces $P[(X,\\ Y) \\in A]$ es el volumen debajo de esta superficie y sobre la región $A$, similar al área bajo una curva en el caso de una sola variable aleatoria. Esto se ilustra en la siguiente figura..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f50dda",
   "metadata": {},
   "source": [
    "![Image 1](resources/imgs_cap5/img_cap5_01.png)\n",
    "\n",
    "\\begin{align*}\n",
    "    P[(X,\\ Y) \\in A] = \\text{volumen bajo la superficie de densidad sobre $A$}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055fba2a",
   "metadata": {},
   "source": [
    "**Definición:** Las **funciones de densidad de probabilidad marginal** de $X$ e $Y$, denotadas por $f_{x}(x)$ y $f_{y}(y)$, respectivamente, estan dadas por"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acef024",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "    f_{x}(x) = \\int_{-\\infty}^{\\infty} f(x,\\ y)\\ dy && \\text{para -$\\infty < x < \\infty$}\n",
    "\\end{align*}\n",
    "$\\\\$\n",
    "\\begin{align*}\n",
    "    f_{y}(y) = \\int_{-\\infty}^{\\infty} f(x,\\ y)\\ dx && \\text{para -$\\infty < x < \\infty$}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d4fd54",
   "metadata": {},
   "source": [
    "### Variables aleatorias independientes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30896513",
   "metadata": {},
   "source": [
    "**Definición:** Se dice que dos variables aleatorias $X$ e $Y$ son **independientes** si por cada par de valores $x$ e $y$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b565ad",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "    p(x,\\ y) = p_{x}(x) \\cdot p_{y}(y) && \\text{cuando $X$ e $Y$ son discretas} \\\\\n",
    "    \\text{o} \\\\\n",
    "    f(x,\\ y) = f_{x}(x) \\cdot f_{y}(y) && \\text{cuando $X$ e $Y$ son continuas}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8773912f",
   "metadata": {},
   "source": [
    "Si las ecuaciones anteriores no se satisface con todos los pares $(x,\\ y)$, entonces se dice que $X$ e $Y$ son **dependientes.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877fad20",
   "metadata": {},
   "source": [
    "### Más de dos variables aleatorias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07b2e17",
   "metadata": {},
   "source": [
    "**Definición:** Si $X_{1},\\ X_{2},...,X_{n}$ son variables aleatorias discretas, la función de masa de probabilidad conjunta de las variables es la función"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d7e2b2",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "    p(x_{1},\\ x_{2},...,x_{n}) = P(X_{1},\\ X_{2},...,X_{n} = x_{n})\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b670c37",
   "metadata": {},
   "source": [
    "Si las variables son continuas, la función de densidad de probabilidad conjunta $X_{1},\\ldots,X_{n}$ es la función $f(x_{1},\\ x_{2},\\ldots,x_{n})$ tal que para $n$ intervalos cualesquiera $[a_{1},\\ b_{1}],\\ldots,[a_{n},\\ b_{n}]$,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02d6523",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "    P(a_{1} \\le X_{1} \\le b_{1},\\ldots,\\ a_{n} \\le X_{n} \\le b_{n}) = \\int_{a_{1}}^{b_{1}} \\ldots \\int_{a_{n}}^{b_{n}} f(x_{1}, \\ldots, x_{n})\\ dx_{n} \\ldots dx_{1}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642d533b",
   "metadata": {},
   "source": [
    "**Definición:** Se dice que las variables aleatorias $X_{1},\\ X_{2}, \\ldots, X_{n}$ son **independientes** si para cada subconjunto $X_{i_{1}},\\ X_{i_{2}}, \\ldots, X_{i_{k}}$ de las variables (cada par, cada terna, y así sucesivamente), la función de masa de probabilidad conjunta o la función de densidad de probabilidad conjunta del subconjunto es igual al producto de las funciones de masa de probabilidad o las funciones de densidad de probabilidad marginales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba86194e",
   "metadata": {},
   "source": [
    "### Distribuciones condicionales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30002af0",
   "metadata": {},
   "source": [
    "**Definición:** Sean $X$ e $Y$ dos variables aleatorias continuas con función de densidad de probabilidad conjunta $f(x,\\ y)$ y función de densidad de probabilidad marginal $X,\\ f_{x}(x)$. Entonces para cualquier valor $x$ de $X$ para el cual $f_{x}(x) > 0$, la **función de densidad de probabilidad condicional de $Y$ dado que $X = x$** es"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7b9b44",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "    f_{Y|X}(y|x) = \\frac{f(x,\\ y)}{f_{x}(x)} && -\\infty < y < \\infty\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100be448",
   "metadata": {},
   "source": [
    "Si $X$ e $Y$ son discretas, al reemplazar las funciones de densidad de probabilidad por funciones de masa de probabilidad en esta definición se obtiene la **función de masa de probabilidad condicional $Y$ cuando $X = x.$**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16821804",
   "metadata": {},
   "source": [
    "## 5.2 Valores esperados, covarianza y correlación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0155ec8e",
   "metadata": {},
   "source": [
    "**Proposición:** Sean $X$ e $Y$ variables aleatorias conjuntamente distribuidas con función de masa de probabilidad $p(x,\\ y)$ o función de densidad de probabilidad $f(x,\\ y)$ ya sea que las variables sean discretas o continuas. Entonces el valor esperado de una función $h(X,\\ Y)$ denotada por $E[h(X,\\ Y)]$ o $\\mu_{h(X,\\ Y)}$ esta dada por"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc65dfba",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "  E[h(X,\\ Y)] =\n",
    "    \\begin{cases}\n",
    "      \\sum_{x} \\sum_{y} h(x,\\ y) \\cdot p(x,\\ y) & \\text{si $X$ e $Y$ son discretas} \\\\\n",
    "      \\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} h(x,\\ y) \\cdot f(x,\\ y)\\ dx\\ dy & \\text{si $X$ e $Y$ son continuas}\n",
    "    \\end{cases}       \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7934fa3a",
   "metadata": {},
   "source": [
    "El método de calcular el valor esperado de una función $h(X_{1},\\ldots,X_{n})$ de $n$ variables aleatorias es similar al de dos variables aleatorias. Si las X_{i} son discretas, $E[h(X_{1},\\ldots,X_{n})]$ es una suma de $n$ dimensiones; si las $X_{i}$ son continuas, es una integral de $n$ dimensiones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf97aa67",
   "metadata": {},
   "source": [
    "### Covarianza"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb53689",
   "metadata": {},
   "source": [
    "**Definición:** La **covarianza** entre dos variables aleatorias $X$ e $Y$ es"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebdbf3a",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    " Cov(X,\\ Y) &= E[(X - \\mu_{X})(Y-\\mu_{Y})] \\\\\n",
    "      &= \\begin{cases}\n",
    "          \\sum_{x} \\sum_{y} (x-\\mu_{X})(y-\\mu_{Y}) p(x,\\ y) & \\text{$X,\\ Y$ discretas} \\\\\n",
    "          \\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} (x-\\mu_{X}) (y-\\mu_{Y}) f(x,\\ y)\\ dx\\ dy & \\text{$X,\\ Y$ continuas}\n",
    "          \\end{cases}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af536c9",
   "metadata": {},
   "source": [
    "**Proposición:** $$Cov(X,\\ Y) = E(XY) - \\mu_{X} \\cdot \\mu_{Y}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6f484e",
   "metadata": {},
   "source": [
    "### Correlación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d55ac90",
   "metadata": {},
   "source": [
    "**Definición:** El **coeficiente de correlación** de $X$ e $Y$, denotado por $Corr(X,\\ Y)$, $\\rho_{X,Y}$, o simplemente $\\rho$, esta definido por"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e4ca81",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "    \\rho_{X,Y} = \\frac{Cov(X,\\ Y)}{\\sigma_{X} \\cdot \\sigma_{Y}}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15201a70",
   "metadata": {},
   "source": [
    "**Proposición:**\n",
    "1. Si $a$ y $c$ son ambas positivas o ambas negativas, $$Corr(aX + b, cY + d) = Corr(X,\\ Y)$$\n",
    "2. Para dos variables aleatorias $X$ e $Y$ cualesquiera, $-1 \\le Corr(X,\\ Y) \\le 1.$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077d6992",
   "metadata": {},
   "source": [
    "**Proposición:**\n",
    "1. Si $X$ e $Y$ son independientes, entonces $\\rho = 0$, pero $\\rho = 0$ implica independencia.\n",
    "2. $\\rho = 1$ o $-1 \\Leftrightarrow Y = aX + b$ con algunos números $a$ y $b$ con $a \\neq 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b128aad0",
   "metadata": {},
   "source": [
    "## 5.3 Estadísticos y sus distribuciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e4ed8e",
   "metadata": {},
   "source": [
    "**Definición:** Un **estadístico** es cualquier cantidad cuyo valor puede ser calculado a partir de datos muestrales. Antes de obtener los datos, existe incertidumbre sobre que valor de cualquier estadístico particular resultara. Por consiguiente, un estadístico es una variable aleatoria y sera denotado por una letra mayúscula; para representar el valor calculado u observado del estadístico se utiliza una letra minúscula."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1082be",
   "metadata": {},
   "source": [
    "### Muestras aleatorias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb9288f",
   "metadata": {},
   "source": [
    "**Definición:** Se dice que las variables aleatorias $X_{1},\\ X_{2},\\ldots,X_{n}$ forman una **muestra aleatoria** (simple) de tamaño $n$ si\n",
    "1. Las $X_{i}$ son variables aleatorias independientes.\n",
    "2. Cada $X_{i}$ tiene la misma distribución de probabilidad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bb5956",
   "metadata": {},
   "source": [
    "### Deducción de una distribución de muestreo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77e8850",
   "metadata": {},
   "source": [
    "Se pueden utilizar reglas de probabilidad para obtener la distribución de un estadístico siempre que sea una función \"bastante simple\" de las $X_{i}$ y existen relativamente pocos valores $X$ diferentes en la población o bien la distribución de la población tiene una forma \"accesible\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4e996f",
   "metadata": {},
   "source": [
    "### Experimentos de simulación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2016e7",
   "metadata": {},
   "source": [
    "El segundo método de obtener información sobre distribución de muestreo de un estadístico es realizar un experimento de simulación. Este método casi siempre se utiliza cuando una derivación vía reglas de probabilidad es demasiado difícil o complicada de realizar. Tal experimento virtualmente se realiza siempre con la ayuda de una computadora. Las siguientes características de un experimento deben ser especificadas:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7f0dec",
   "metadata": {},
   "source": [
    "1. El estadístico de interés ($\\overline{X}$, $S$, una media recortada particular, etc.)\n",
    "2. La distribucion de la población (normal con $\\mu = 100$ y $\\sigma = 15$, uniforme con límite inferior $A = 5$ y superior $B = 10$, etc.)\n",
    "3. El tamaño de muestra $n$ (e.g. $n = 10$ o $n = 50$)\n",
    "4. El número de replicas $k$ (número de muestras que serán obtenidas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891cf58f",
   "metadata": {},
   "source": [
    "## 5.4 Distribución de la media muestral"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92de8882",
   "metadata": {},
   "source": [
    "**Proposición:** Sean $X_{1},\\ X_{2},\\ldots,\\ X_{n}$ una muestra aleatoria de una distribución con valor medio $\\mu$ y desviación estándar $\\sigma$. Entonces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e415fa06",
   "metadata": {},
   "source": [
    "1. $E(\\overline{X}) = \\mu_{\\overline{X}} = \\mu$\n",
    "2. $V(\\overline{X}) = \\sigma_{\\overline{X}}^{2} = \\sigma^{2}/n\\ $ y $\\ \\sigma_{\\overline{X}} = \\sigma/\\sqrt{n}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63256daa",
   "metadata": {},
   "source": [
    "Además, con $T_{0} = X_{1} + \\ldots + X_{n}$ (el total de la muestra), $E(T_{0}) = n\\mu$, $V(T_{0}) = n\\sigma^{2}$ y $\\sigma_{T_{0}} = \\sqrt{n}\\sigma.$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84150f7f",
   "metadata": {},
   "source": [
    "### El caso de una distribución de población normal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc40472b",
   "metadata": {},
   "source": [
    "**Proposición:** Sean $X_{1},\\ X_{2},\\ldots,\\ X_{n}$ una muestra aleatoria de una distribución *normal* con media $\\mu$ y desviación estándar $\\sigma$. Entonces cualquier $n,\\ \\overline{X}$ esta normalmente distribuida (con media $\\mu$ y desviación estándar $\\sigma/\\sqrt{n}$), como $T_{0}$ (con media $n\\mu$ y desviación estándar $\\sqrt{n}\\sigma$). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffac1b06",
   "metadata": {},
   "source": [
    "---\n",
    "Se sabe todo lo que se tiene que saber sobre las distribuciones $\\overline{X}$ y $T_{0}$ cuando la distribución de la población es normal. En particular, las probabilidad tales como $P(a \\le \\overline{X} \\le b)$ y $P(c \\le T_{0} \\le d)$ se obtienen simplemente estandarizando. La siguiente figura ilustra la proposición."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e478de",
   "metadata": {},
   "source": [
    "![Image 2](resources/imgs_cap5/img_cap5_02.png)\n",
    "\\begin{align*}\n",
    "    \\text{Distribución de población normal y distribuciones muestrales $\\overline{X}$}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbaf8774",
   "metadata": {},
   "source": [
    "### Teorema del límite central"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89a7cf9",
   "metadata": {},
   "source": [
    "Cuando $X_{i}$ estan normalmente distribuidas, también lo esta $\\overline{X}$ con cada tamaño de muestra $n$. Una conjetura razonable es que si $n$ es grande, una curva normal apropiada representara de forma mas  o menos aproximada la distribución real de $\\overline{X}$. El planteamiento formal de este resultado es el mas importante teorema de probabilidad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bd04fb",
   "metadata": {},
   "source": [
    "**Teorema:** Sea $X_{1},\\ X_{2},\\ldots,X_{n}$ una muestra aleatoria de una distribución con media $\\mu$ y varianza $\\sigma^{2}$. Entonces si $n$ es suficientemente grande, $\\overline{X}$ tiene aproximadamente una distribución normal con $\\mu_{\\overline{X}} = \\mu$ y $\\sigma_{\\overline{X}}^{2} = \\sigma_{2}/n$, y $T_{0}$ también tiene aproximadamente una distribución normal con $\\mu_{T_{0}} = n\\mu,\\ \\sigma_{T_{0}}^{2} = n \\sigma^{2}$. Mientras mas grande es el valor de $n$, mejor es la aproximación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8fee7a",
   "metadata": {},
   "source": [
    "![Image 3](resources/imgs_cap5/img_cap5_03.png)\n",
    "\\begin{align*}\n",
    "    \\text{Teorma del límite central ilustrado}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb73b771",
   "metadata": {},
   "source": [
    "El *TLC* da una idea de por que muchas variables aleatorias tienen distribuciones de probabilidad que son aproximadamente normales. Por ejemplo, el error de medición en un experimento científico puede ser considerado como la suma de varias perturbaciones y errores subyacentes de pequeña magnitud."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd348e8",
   "metadata": {},
   "source": [
    "Una dificultad práctica al aplicar el teorema del límite central es saber cuando *n* es suficientemente grande. El problema es que la precisión de la aproximación con una *n* particular depende de la forma de la distribución subyacente original que esta siendo muestreada. Si la distribución subyacente tiene a una curva de densidad normal, entonces la aproximación será buena incluso con *n* pequeña, mientras que si esta lejos de ser normal, entonces se requerira una *n* grande."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfca626",
   "metadata": {},
   "source": [
    "**Regla empírica:** Si $n > 30$, se puede utilizar el teorema del límite central."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e055b690",
   "metadata": {},
   "source": [
    "### Otras aplicaciones del teorema del límite central"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd64537",
   "metadata": {},
   "source": [
    "**Proposición:** Sea $X_{1},\\ X_{2},\\ldots,\\ X_{n}$ una muestra aleatoria de una distribución para la cuál solo los posibles valores positivos $[P(X_{i} > 0) = 1]$. Entonces si $n$ es suficientemente grande, el producto $Y = X_{1} \\cdot X_{2}\\cdot \\ldots \\cdot X_{n}$ tiene aproximandamente una distribución lognormal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d9d8ea",
   "metadata": {},
   "source": [
    "## 5.5 Distribucion de una combinación lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2d638a",
   "metadata": {},
   "source": [
    "La media muestral $\\overline{X}$ y el total muestral $T_{0}$ son casos especiales de un tipo de variable aleatoria que surgen con frecuencia en aplicaciones estadísticas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d478d3bf",
   "metadata": {},
   "source": [
    "**Definición:** Dado un conjunto de $n$ variables aleatorias $X_{1},\\ldots,\\ X_{n}$ y $n$ constantes numéricas $a_{1},\\ldots,\\ a_{n}$, la variable aleatoria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5dfed7",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "    Y = a_{1} X_{1} + \\cdots + a_{n} X_{n} = \\sum_{i = 1}^{n} a_{i} X_{i}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8428df",
   "metadata": {},
   "source": [
    "se llama **combinación lineal** de las $X_{i}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba712abb",
   "metadata": {},
   "source": [
    "---\n",
    "**Proposición:** Sean $X_{1},\\ X_{2},\\ldots,\\ X_{n}$ con valores medios $\\mu_{1},\\ldots,\\ \\mu_{n}$, respectivamente, y varianzas $\\sigma_{1}^{2},\\ldots,\\ \\sigma_{n}^{2}$, respectivamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacc6fc4",
   "metadata": {},
   "source": [
    "1. Si las $X_{i}$ son independientes o no\n",
    "\n",
    "\\begin{align*}\n",
    " E(a_{1} X_{1} + a_{2} X_{2} + \\cdots + a_{n} X_{n} &= a_{1} E(X_{1}) + a_{2} E(X_{2}) + \\cdots + a_{n} E(X_{n}) \\\\\n",
    "      &= a_{1} \\mu_{1} + \\cdots + a_{n} \\mu_{n}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bdd20e",
   "metadata": {},
   "source": [
    "2. Si $X_{1},\\ldots,\\ X_{n}$ son independientes,\n",
    "\n",
    "\\begin{align*}\n",
    " V(a_{1} X_{1} + a_{2} X_{2} + \\cdots + a_{n} X_{n} &= a_{1}^{2} V(X_{1}) + a_{2}^{2} V(X_{2}) + \\cdots + a_{n}^{2} V(X_{n}) \\\\\n",
    "      &= a_{1}^{2} \\sigma_{1}^{2} + \\cdots + a_{n}^{2} \\sigma_{n}^{2}\n",
    "\\end{align*}\n",
    "\n",
    "y\n",
    "\n",
    "\\begin{align*}\n",
    "    \\sigma_{a_{1}X_{1}+\\cdots+a_{n}X_{n}} = \\sqrt{a_{1}^{2}\\sigma_{1}^{2}+\\cdots+a_{n}^{2}\\sigma_{n}^{2}}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9afaf40",
   "metadata": {},
   "source": [
    "3. Son cualquier $X_{1},\\ldots,X_{n}$,\n",
    "\n",
    "\\begin{align*}\n",
    "    V(a_{1}X_{1} + \\cdots + a_{n}X_{n}) = \\sum_{i = 1}^{n} \\sum_{j = 1}^{n} a_{i} a_{j} Cov(X_{i},\\ X_{j})\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d76f128",
   "metadata": {},
   "source": [
    "### Diferencia entre dos variables aleatorias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36618ab6",
   "metadata": {},
   "source": [
    "Un importante caso especial de una combinación lineal se presenta con $n = 2, a_{1} = 1$ y $a_{2} = -1$:\n",
    "\n",
    "\\begin{align*}\n",
    "    Y = a_{1} X_{1} + a_{2} X_{2} = X_{1} - X_{2}\n",
    "\\end{align*}\n",
    "\n",
    "Entonces se tiene el siguiente corolario de la proposición."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa54836",
   "metadata": {},
   "source": [
    "**Corolario:** $E(X_{1} - X_{2}) = E(X_{1}) - E(X_{2})$ para dos variables aleatorias cualesquiera $X_{1}$ y $X_{2}.\\\\ $\n",
    "$V(X_{1} - X_{2}) = V(X_{1}) + V(X_{2})$ si $X_{1}$ y $X_{2}$ son variables aleatorias independientes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed96bb97",
   "metadata": {},
   "source": [
    "### El caso de variables aleatorias normales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3312c374",
   "metadata": {},
   "source": [
    "Cuando las $X_{i}$ forman una muestra aleatoria de una distribución normal, $\\overline{X}$ y $T_{0}$ estan normalmente distribuidas. He aqui un resultado mas general con respecto a combinaciones lineales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46eb8fe",
   "metadata": {},
   "source": [
    "**Proposición:** Si $X_{1},\\ X_{2},\\ldots,\\ X_{n}$ son variables aleatorias independientes normalmente distribuidas (con quiza diferentes medias y/o varianzas), entonces cualquier combinación lineal de las $X_{i}$ también tienen una distribución normal. En particular, la diferencia $X_{1} - X_{2}$ entre dos variables independientes normalmente distribuidas tambien esta distribuida en forma normal."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c08775dc",
   "metadata": {},
   "source": [
    "# *Capitulo 6 - Estimacion puntual*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b712bf41",
   "metadata": {},
   "source": [
    "## INTRODUCCION\n",
    "\n",
    "Dado un parametro de interes, tal como la media $/mu$ o la proporcion $p$ de una poblacion, el objetivo de la estimacion puntual es utilizar una muestra para calcular un numero que representa en cierto sentido una buena suposicion del valor verdadero del parametro. El numero resultante se llama *estimacion puntual.* En la seccion 6.2 se describen e ilustran dos metodos importantes para obtener estimaciones puntuales: el metodo de momentos y el metodo de maxima probabilidad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919efcc3",
   "metadata": {},
   "source": [
    "## 6.1 Algunos conceptos generales de estimacion puntual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cae1b0b",
   "metadata": {},
   "source": [
    "**Definicion:** Una **estimacion puntual** de un parametro $\\theta$ es un numero unico que puede ser considerado como un valor sensible de $\\theta$. Se obtiene una estimacion puntual seleccionando un estadistico apropiado y calculando su valor con los datos muestrales dados. El estadistico seleccionado se llama **estimador puntual** de $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0877f359",
   "metadata": {},
   "source": [
    "### Estimadores insesgados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c4b536",
   "metadata": {},
   "source": [
    "**Definicion:** Se dice que un estimador puntual $\\hat{\\theta}$ es un **estimador insesgado** de $\\theta$ si $E(\\hat{\\theta}) = \\theta$ para todo valor posible de $\\theta$. Si $\\hat{\\theta}$ es insesgado, la diferencia $E(\\hat{\\theta}) - \\theta$ se conoce como el **sesgo** de $\\hat{\\theta}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a18b4c9",
   "metadata": {},
   "source": [
    "---\n",
    "Es decir, $\\hat{\\theta}$ es sesgado si su distribucion de probabilidad (es decir, muestreo) siempre esta \"centrada\" en el valor verdadero del parametro. Supongase que $\\hat{\\theta}$ es un estimador insesgado; entonces si $\\theta = 100$, la distribucion muestral $\\hat{\\theta}$ esta centrada en 100; si $\\theta = 27.5$, en ese caso la distribucion muestral $\\hat{\\theta}$ esta centrada en 27.5, y asi sucesivamente. La siguiente figura ilustra la distribucion de varios estimadores sesgados e insesgados. Observese que \"centrada\" en este caso significa que el valor esperado, no la mediana, de la distribucion de $\\hat{\\theta}$ es igual a $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabde7f7",
   "metadata": {},
   "source": [
    "![Image 1](resources/imgs_cap6/img_cap6_01.png)\n",
    "$$\\text{Funciones de densidad de probabilidad de un estimador sesgado $\\hat{\\theta}_{1}$ y un estimador insesgado $\\hat{\\theta}_{2}$, de un parametro $\\theta$}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbb0d12",
   "metadata": {},
   "source": [
    "**Proposicion:** Cuando $X$ es una variable aleatoria binomial con parametros $n$ y $p$, la proporcion muestral $\\hat{p} = X/n$ es un estimador sesgado de $p$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7154d7af",
   "metadata": {},
   "source": [
    "**Principio de estimacion insesgada**  \n",
    "Cuando se elige entre varios estimadores diferentes de $\\theta$, se elige uno insesgado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8e3c7a",
   "metadata": {},
   "source": [
    "**Proposicion:** Sea $X_{1},\\ X_{2}, \\ldots,\\ X_{n}$ una muestra aleatoria de una distribucion con media $\\mu$ y varianza $\\sigma^{2}$. Entonces el estimador\n",
    "$$\\hat{\\sigma}^{2} = S^{2} = \\frac{\\sum(X_{i} - \\overline{X})^{2}}{n -1}$$\n",
    "es un estimador insesgado de $\\sigma^{2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9c4a10",
   "metadata": {},
   "source": [
    "**Demostracion:**\n",
    "Para cualquier variable aleatoria $Y,\\ V(Y) = E(Y^{2}) - [E(Y)]^{2}$, por lo tanto $E(Y^{2}) = V(Y) + [E(Y)]^{2}$. Aplicando esto a\n",
    "$$ S^{2} = \\frac{1}{n-1} \\left[\\sum X_{i}^{2} - \\frac{(\\sum X_{i})^{2}}{n}\\right] $$\n",
    "se obtiene\n",
    "\\begin{align*}\n",
    "    E(S^{2}) &= \\frac{1}{n-1} \\left(\\sum E(X_{i}^{2}) - \\frac{1}{n} E[(\\sum X_{i})^{2}] \\right) \\\\\n",
    "    &= \\frac{1}{n-1} \\left( \\sum(\\sigma^{2} + \\mu^{2}) - \\frac {1}{n} \\{V(\\sum X_{i}) + [E(\\sum X_{i})]^{2}\\} \\right) \\\\\n",
    "    &= \\frac{1}{n-1} \\left( n \\sigma^{2} + n \\mu^{2} - \\frac{1}{n} n \\sigma^{2} - \\frac{1}{n} (n \\mu)^{2} \\right) \\\\\n",
    "    &= \\frac{1}{n-1} \\{ n \\sigma^{2} - \\sigma^{2} \\} = \\sigma^{2}\\ \\text{(como se desea)}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3b32fa",
   "metadata": {},
   "source": [
    "---\n",
    "**Proposicion:** Si $X_{1},\\ X_{2}, \\ldots,\\ X_{n}$ es una muestra aleatoria tomada de una distribucion con media $\\mu$, entonces $\\overline{X}$ es un estimador sesgado de $\\mu$. Si ademas la distribucion es continua y simetrica, entonces $\\tilde{X}$ y cualquier media recortada tambien son estimadores insesgados de $\\mu$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4977464",
   "metadata": {},
   "source": [
    "### Estimadores con varianza minima"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc2b71b",
   "metadata": {},
   "source": [
    "**Principio de estimacion insesgada con varianza minima.**  \n",
    "Entre todos los estimadores de $\\theta$ insesgados, se selecciona el de varianza minima. El $\\hat{\\theta}$ resultante se llama **estimador insesgado con varianza minima (EIVM)** de $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03582ac0",
   "metadata": {},
   "source": [
    "---\n",
    "La siguiente figura ilustra las funciones de densidad de probablidad de los dos estimadores insesgados, donde $\\hat{\\theta}_{1}$ tiene una varianza mas pequena que $\\hat{\\theta}_{2}$. Entonces es mas probable que $\\hat{\\theta}_{1}$ produzca una estimacion proxima al valor verdadero $\\theta$ que $\\hat{\\theta}_{2}$. El estimador insesgado con varianza minima es, en cierto sentido, el que tiene mas probabildiades entre todos los estimadores insesgados de producir una estimacion cercana al verdadero $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48b78a1",
   "metadata": {},
   "source": [
    "![Image 2](resources/imgs_cap6/img_cap6_02.png)\n",
    "$$ \\text{Graficas de las funciones de densidad de probabilidad de dos estimadores insesgados diferentes.} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d065ebf",
   "metadata": {},
   "source": [
    "**Teorema:** Sea $X_{1},\\ldots,\\ X_{n}$ una muestra aleatoria tomada de una distribucion normal con parametros $\\mu$ y $\\sigma$. Entonces el estimador $\\hat{\\mu} = \\overline{X}$ es el estimador insesgado con varianza minima para $\\mu$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da13f7c0",
   "metadata": {},
   "source": [
    "### Algunas complicaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917e5e8f",
   "metadata": {},
   "source": [
    "El ultimo teorema no dice que al estimar la media $\\mu$ de una poblacion, se debera utilizar el estimador $\\overline{X}$ independientemente de la distribucion que se esta muestreando."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3592869",
   "metadata": {},
   "source": [
    "El mejor estimador de $\\mu$ depende crucialmente de que distribucion esta siendo muestreada. En particular,\n",
    "1. Si la muestra aleatoria proviene de una distribucion normal, en ese caso $\\overline{X}$ es el mejor de los cuatro estimadores, puesto que tiene una varianza minima entre todos los estimadores insesgados.\n",
    "2. Si la muestra aleatoria proviene de una distribucion de Cauchy, entonces $\\overline{X}$ y $\\overline{X}_{e}$ son estimadores terribles de $\\mu$, en tanto que $\\tilde{X}$ es bastante bueno (es estimador insesgado con varianza minima no es conocido); $\\overline{X}$ es malo porque es muy sensible a las observaciones subyacentes y las colas gruesas de la distribucion de Cauchy hacen que sea improbable que aparezcan tales observaciones en cualquier muestra.\n",
    "3. Si la distribucion subyacente es uniforme, el mejor estimador es $\\overline{X}_{e}$; este estimador esta influido en gran medida por las observaciones subyacentes, pero la carencia de colas hace que tales observaciones sean imposibles.\n",
    "4. En ninguna de estas tres situaciones es mejor la media recortada pero funciona razonablemente bien en las tres. Es decir, $\\overline{X}_{rec(10)}$ no sufre demasiado en comparacion con el mejor procedimiento en cualquier de las tres situaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82178642",
   "metadata": {},
   "source": [
    "### Reporte de una estimacion puntual: el error estandar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188ae5e2",
   "metadata": {},
   "source": [
    "**Definicion:** El **error estandar** de una parametro $\\hat{\\theta}$ es su desviacion estandar $\\sigma_{\\hat{\\theta}} = \\sqrt{V(\\hat{\\theta})}$. Este es la magnitud de una desviacion tipica o representativa entre una estimacion y el valor de $\\theta$. Si el error estandar implica parametros desconocidos cuyos valores pueden ser estimados, la sustitucion de estas estimaciones en $\\sigma_{\\hat{\\theta}}$ da el **error estandar estimado** (desviacion estandar estimada) del estimador. El error estandar estimado puede ser denotado por $\\hat{\\sigma}_{\\hat{\\theta}}$ (el $\\hat{}$ sobre $\\sigma$ recalca que $\\sigma_{\\hat{\\theta}}$ esta siendo estimada) o por $s_{\\hat{\\theta}}$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c08775dc",
   "metadata": {},
   "source": [
    "# *Capítulo 6 - Estimación puntual*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b712bf41",
   "metadata": {},
   "source": [
    "## Introducción\n",
    "\n",
    "Dado un parametro de interés, tal como la media $/mu$ o la proporción $p$ de una población, el objetivo de la estimación puntual es utilizar una muestra para calcular un número que representa en cierto sentido una buena suposición del valor verdadero del parámetro. El número resultante se llama *estimación puntual.* En la sección 6.2 se describen e ilustran dos métodos importantes para obtener estimaciones puntuales: el método de momentos y el método de máxima probabilidad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919efcc3",
   "metadata": {},
   "source": [
    "## 6.1 Algunos conceptos generales de estimación puntual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cae1b0b",
   "metadata": {},
   "source": [
    "**Definición:** Una **estimación puntual** de un parámetro $\\theta$ es un número único que puede ser considerado como un valor sensible de $\\theta$. Se obtiene una estimación puntual seleccionando un estadístico apropiado y calculando su valor con los datos muestrales dados. El estadístico seleccionado se llama **estimador puntual** de $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0877f359",
   "metadata": {},
   "source": [
    "### Estimadores insesgados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c4b536",
   "metadata": {},
   "source": [
    "**Definición:** Se dice que un estimador puntual $\\hat{\\theta}$ es un **estimador insesgado** de $\\theta$ si $E(\\hat{\\theta}) = \\theta$ para todo valor posible de $\\theta$. Si $\\hat{\\theta}$ es insesgado, la diferencia $E(\\hat{\\theta}) - \\theta$ se conoce como el **sesgo** de $\\hat{\\theta}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a18b4c9",
   "metadata": {},
   "source": [
    "---\n",
    "Es decir, $\\hat{\\theta}$ es sesgado si su distribución de probabilidad (es decir, muestreo) siempre esta \"centrada\" en el valor verdadero del parámetro. Supóngase que $\\hat{\\theta}$ es un estimador insesgado; entonces si $\\theta = 100$, la distribución muestral $\\hat{\\theta}$ esta centrada en 100; si $\\theta = 27.5$, en ese caso la distribución muestral $\\hat{\\theta}$ esta centrada en 27.5, y asi sucesivamente. La siguiente figura ilustra la distribución de varios estimadores sesgados e insesgados. Observese que \"centrada\" en este caso significa que el valor esperado, no la mediana, de la distribución de $\\hat{\\theta}$ es igual a $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabde7f7",
   "metadata": {},
   "source": [
    "![Image 1](resources/imgs_cap6/img_cap6_01.png)\n",
    "$$\\text{Funciones de densidad de probabilidad de un estimador sesgado $\\hat{\\theta}_{1}$ y un estimador insesgado $\\hat{\\theta}_{2}$, de un parámetro $\\theta$}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbb0d12",
   "metadata": {},
   "source": [
    "**Proposición:** Cuando $X$ es una variable aleatoria binomial con parámetros $n$ y $p$, la proporción muestral $\\hat{p} = X/n$ es un estimador sesgado de $p$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7154d7af",
   "metadata": {},
   "source": [
    "**Principio de estimación insesgada**  \n",
    "Cuando se elige entre varios estimadores diferentes de $\\theta$, se elige uno insesgado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8e3c7a",
   "metadata": {},
   "source": [
    "**Proposición:** Sea $X_{1},\\ X_{2}, \\ldots,\\ X_{n}$ una muestra aleatoria de una distribución con media $\\mu$ y varianza $\\sigma^{2}$. Entonces el estimador\n",
    "$$\\hat{\\sigma}^{2} = S^{2} = \\frac{\\sum(X_{i} - \\overline{X})^{2}}{n -1}$$\n",
    "es un estimador insesgado de $\\sigma^{2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9c4a10",
   "metadata": {},
   "source": [
    "**Demostracion:**\n",
    "Para cualquier variable aleatoria $Y,\\ V(Y) = E(Y^{2}) - [E(Y)]^{2}$, por lo tanto $E(Y^{2}) = V(Y) + [E(Y)]^{2}$. Aplicando esto a\n",
    "$$ S^{2} = \\frac{1}{n-1} \\left[\\sum X_{i}^{2} - \\frac{(\\sum X_{i})^{2}}{n}\\right] $$\n",
    "se obtiene\n",
    "\\begin{align*}\n",
    "    E(S^{2}) &= \\frac{1}{n-1} \\left(\\sum E(X_{i}^{2}) - \\frac{1}{n} E[(\\sum X_{i})^{2}] \\right) \\\\\n",
    "    &= \\frac{1}{n-1} \\left( \\sum(\\sigma^{2} + \\mu^{2}) - \\frac {1}{n} \\{V(\\sum X_{i}) + [E(\\sum X_{i})]^{2}\\} \\right) \\\\\n",
    "    &= \\frac{1}{n-1} \\left( n \\sigma^{2} + n \\mu^{2} - \\frac{1}{n} n \\sigma^{2} - \\frac{1}{n} (n \\mu)^{2} \\right) \\\\\n",
    "    &= \\frac{1}{n-1} \\{ n \\sigma^{2} - \\sigma^{2} \\} = \\sigma^{2}\\ \\text{(como se desea)}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3b32fa",
   "metadata": {},
   "source": [
    "---\n",
    "**Proposición:** Si $X_{1},\\ X_{2}, \\ldots,\\ X_{n}$ es una muestra aleatoria tomada de una distribución con media $\\mu$, entonces $\\overline{X}$ es un estimador sesgado de $\\mu$. Si además la distribución es continua y simétrica, entonces $\\tilde{X}$ y cualquier media recortada también son estimadores insesgados de $\\mu$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4977464",
   "metadata": {},
   "source": [
    "### Estimadores con varianza mínima"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc2b71b",
   "metadata": {},
   "source": [
    "**Principio de estimación insesgada con varianza mínima.**  \n",
    "Entre todos los estimadores de $\\theta$ insesgados, se selecciona el de varianza mínima. El $\\hat{\\theta}$ resultante se llama **estimador insesgado con varianza mínima (EIVM)** de $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03582ac0",
   "metadata": {},
   "source": [
    "---\n",
    "La siguiente figura ilustra las funciones de densidad de probablidad de los dos estimadores insesgados, donde $\\hat{\\theta}_{1}$ tiene una varianza más pequeña que $\\hat{\\theta}_{2}$. Entonces es mas probable que $\\hat{\\theta}_{1}$ produzca una estimación próxima al valor verdadero $\\theta$ que $\\hat{\\theta}_{2}$. El estimador insesgado con varianza mínima es, en cierto sentido, el que tiene mas probabildiades entre todos los estimadores insesgados de producir una estimación cercana al verdadero $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48b78a1",
   "metadata": {},
   "source": [
    "![Image 2](resources/imgs_cap6/img_cap6_02.png)\n",
    "$$ \\text{Gráficas de las funciones de densidad de probabilidad de dos estimadores insesgados diferentes.} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d065ebf",
   "metadata": {},
   "source": [
    "**Teorema:** Sea $X_{1},\\ldots,\\ X_{n}$ una muestra aleatoria tomada de una distribución normal con parámetros $\\mu$ y $\\sigma$. Entonces el estimador $\\hat{\\mu} = \\overline{X}$ es el estimador insesgado con varianza mínima para $\\mu$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da13f7c0",
   "metadata": {},
   "source": [
    "### Algunas complicaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917e5e8f",
   "metadata": {},
   "source": [
    "El último teorema no dice que al estimar la media $\\mu$ de una población, se deberá utilizar el estimador $\\overline{X}$ independientemente de la distribución que se esta muestreando."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3592869",
   "metadata": {},
   "source": [
    "El mejor estimador de $\\mu$ depende crucialmente de que distribución esta siendo muestreada. En particular,\n",
    "1. Si la muestra aleatoria proviene de una distribución normal, en ese caso $\\overline{X}$ es el mejor de los cuatro estimadores, puesto que tiene una varianza mínima entre todos los estimadores insesgados.\n",
    "2. Si la muestra aleatoria proviene de una distribución de Cauchy, entonces $\\overline{X}$ y $\\overline{X}_{e}$ son estimadores terribles de $\\mu$, en tanto que $\\tilde{X}$ es bastante bueno (es estimador insesgado con varianza mínima no es conocido); $\\overline{X}$ es malo porque es muy sensible a las observaciones subyacentes y las colas gruesas de la distribución de Cauchy hacen que sea improbable que aparezcan tales observaciones en cualquier muestra.\n",
    "3. Si la distribución subyacente es uniforme, el mejor estimador es $\\overline{X}_{e}$; este estimador esta influido en gran medida por las observaciones subyacentes, pero la carencia de colas hace que tales observaciones sean imposibles.\n",
    "4. En ninguna de estas tres situaciones es mejor la media recortada pero funciona razonablemente bien en las tres. Es decir, $\\overline{X}_{rec(10)}$ no sufre demasiado en comparación con el mejor procedimiento en cualquier de las tres situaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82178642",
   "metadata": {},
   "source": [
    "### Reporte de una estimación puntual: el error estándar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188ae5e2",
   "metadata": {},
   "source": [
    "**Definición:** El **error estándar** de una parámetro $\\hat{\\theta}$ es su desviación estándar $\\sigma_{\\hat{\\theta}} = \\sqrt{V(\\hat{\\theta})}$. Este es la magnitud de una desviación típica o representativa entre una estimación y el valor de $\\theta$. Si el error estándar implica parámetros desconocidos cuyos valores pueden ser estimados, la sustitución de estas estimaciones en $\\sigma_{\\hat{\\theta}}$ da el **error estándar estimado** (desviación estandar estimada) del estimador. El error estándar estimado puede ser denotado por $\\hat{\\sigma}_{\\hat{\\theta}}$ (el $\\hat{}$ sobre $\\sigma$ recalca que $\\sigma_{\\hat{\\theta}}$ esta siendo estimada) o por $s_{\\hat{\\theta}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1e631e",
   "metadata": {},
   "source": [
    "## 6.2 Métodos de estimación puntual"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
